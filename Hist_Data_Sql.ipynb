{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50393b5e-179e-46db-ada5-466942997f86",
   "metadata": {},
   "source": [
    "# STAGE 2 - Automated Data Ingestion and Cleaning: Excel to MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ba8dd-0305-4e76-abbe-a3cbe8d8ad94",
   "metadata": {},
   "source": [
    "**Import Libraries:**\n",
    "* **pandas:** Used for reading and processing Excel files.\n",
    "* **pymysql:** Connects and interacts with a MySQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e1efe0-9f53-49a8-8b4e-17a576b8f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d430d455-d790-414d-8283-e5d25abf6ade",
   "metadata": {},
   "source": [
    "**Define Company Details:**\n",
    "\n",
    "Each company has a file path (to its Excel file), a company name, and a table name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c70f4a5-889c-4bfe-beba-b7497ca029d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of companies with their respective Excel file paths and table names\n",
    "companies = [{\"file_path\": r\"E:\\Stock Data\\Indian Hotels.xlsx\", \"company_name\": \"Indian Hotels\", \"table_name\": \"Indian_Hotels\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Nelco.xlsx\", \"company_name\": \"Nelco\", \"table_name\": \"Nelco\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Rallis India.xlsx\", \"company_name\": \"Rallis India\", \"table_name\": \"Rallis_India\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Tata Chemicals.xlsx\", \"company_name\": \"Tata Chemicals\", \"table_name\": \"Tata_Chemicals\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Tata Power.xlsx\", \"company_name\": \"Tata Power\", \"table_name\": \"Tata_Power\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Tata Communication.xlsx\", \"company_name\": \"Tata Communication\", \"table_name\": \"Tata_Communication\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Tata Consumer.xlsx\", \"company_name\": \"Tata Consumer\", \"table_name\": \"Tata_Consumer\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Tata Elxsi.xlsx\", \"company_name\": \"Tata Elxsi\", \"table_name\": \"Tata_Elxsi\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Tata Investment Corp.xlsx\", \"company_name\": \"Tata Investment Corp\", \"table_name\": \"Tata_Investment_Corp\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Tata Motors.xlsx\", \"company_name\": \"Tata Motors\", \"table_name\": \"Tata_Motors\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Titan.xlsx\", \"company_name\": \"Titan\", \"table_name\": \"Titan\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Tata Steel.xlsx\", \"company_name\": \"Tata Steel\", \"table_name\": \"Tata_Steel\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Trent.xlsx\", \"company_name\": \"Trent\", \"table_name\": \"Trent\"},\n",
    "    {\"file_path\": r\"E:\\Stock Data\\Voltas.xlsx\", \"company_name\": \"Voltas\", \"table_name\": \"Voltas\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d13508d-e99e-43c6-a67f-7051c3e69630",
   "metadata": {},
   "source": [
    "**Database Configuration:**\n",
    "\n",
    "Stores the database connection details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d31ae15-356d-4ecf-ba63-574b76ccd09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database configuration\n",
    "db_config = {'host': 'localhost', 'user': 'root', 'password': 'Onmyway09@', 'database': 'STOCK_PREDICTION'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc829a-ce4e-4add-9529-7f488920643c",
   "metadata": {},
   "source": [
    "**The `process_company_data` function processes stock data for a single company. Here's what it does:**\r\n",
    "\r\n",
    "1. **Reads the Excel File**: Loads the company's stock data from the specified fil.\r\n",
    "\r\n",
    "2. **Cleans Column Names**: Strips extra spaces from column headrs.\r\n",
    "\r\n",
    "3. **Formats Dates**: Converts the 'Date' column to a standard YYYY-MM-DD format and removes invalid enries.\r\n",
    "\r\n",
    "4. **Cleans Data**: Removes commas from numeric columns and converts them to proper numeri types.\r\n",
    "\r\n",
    "5. **Handles Missing Values**: Replaces NaN valus with 0.\r\n",
    "\r\n",
    "6. **Adds Company Name**: Adds a column to label the data with the comany's name.\r\n",
    "\r\n",
    "7. **Connects to MySQL**: Establishes a databae connection.\r\n",
    "\r\n",
    "8. **Creates a Table**: Ensures a table for the company's data exists n the database.\r\n",
    "\r\n",
    "9. **Inserts Data**: Adds the cleaned data to te database table.\r\n",
    "\r\n",
    "10. **Handles Errors**: Logs any database errors and ensures conheir data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b5c586a-55aa-4c64-ad01-9da08db0dd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Indian_Hotels' is ready.\n",
      "Data inserted successfully into the 'Indian_Hotels' table for Indian Hotels.\n",
      "\n",
      "\n",
      "Table 'Nelco' is ready.\n",
      "Data inserted successfully into the 'Nelco' table for Nelco.\n",
      "\n",
      "\n",
      "Table 'Rallis_India' is ready.\n",
      "Data inserted successfully into the 'Rallis_India' table for Rallis India.\n",
      "\n",
      "\n",
      "Table 'Tata_Chemicals' is ready.\n",
      "Data inserted successfully into the 'Tata_Chemicals' table for Tata Chemicals.\n",
      "\n",
      "\n",
      "Table 'Tata_Power' is ready.\n",
      "Data inserted successfully into the 'Tata_Power' table for Tata Power.\n",
      "\n",
      "\n",
      "Table 'Tata_Communication' is ready.\n",
      "Data inserted successfully into the 'Tata_Communication' table for Tata Communication.\n",
      "\n",
      "\n",
      "Table 'Tata_Consumer' is ready.\n",
      "Data inserted successfully into the 'Tata_Consumer' table for Tata Consumer.\n",
      "\n",
      "\n",
      "Table 'Tata_Elxsi' is ready.\n",
      "Data inserted successfully into the 'Tata_Elxsi' table for Tata Elxsi.\n",
      "\n",
      "\n",
      "Table 'Tata_Investment_Corp' is ready.\n",
      "Data inserted successfully into the 'Tata_Investment_Corp' table for Tata Investment Corp.\n",
      "\n",
      "\n",
      "Table 'Tata_Motors' is ready.\n",
      "Data inserted successfully into the 'Tata_Motors' table for Tata Motors.\n",
      "\n",
      "\n",
      "Table 'Titan' is ready.\n",
      "Data inserted successfully into the 'Titan' table for Titan.\n",
      "\n",
      "\n",
      "Table 'Tata_Steel' is ready.\n",
      "Data inserted successfully into the 'Tata_Steel' table for Tata Steel.\n",
      "\n",
      "\n",
      "Table 'Trent' is ready.\n",
      "Data inserted successfully into the 'Trent' table for Trent.\n",
      "\n",
      "\n",
      "Table 'Voltas' is ready.\n",
      "Data inserted successfully into the 'Voltas' table for Voltas.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to process and insert data for a single company\n",
    "def process_company_data(company):\n",
    "    file_path = company[\"file_path\"]\n",
    "    company_name = company[\"company_name\"]\n",
    "    table_name = company[\"table_name\"]\n",
    "\n",
    "    # Read the Excel file\n",
    "    try:\n",
    "        data = pd.read_excel(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return\n",
    "\n",
    "    # Clean column names by stripping leading/trailing spaces\n",
    "    data.columns = data.columns.str.strip()\n",
    "\n",
    "    # Clean the data\n",
    "    # Convert 'Date' to datetime format and ensure only YYYY-MM-DD format\n",
    "    data['Date'] = pd.to_datetime(data['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "    data = data[data['Date'].notna()]  # Drop rows with invalid dates\n",
    "\n",
    "    # Clean columns with commas or non-numeric characters\n",
    "    columns_to_clean = ['52W H', 'VOLUME', 'VALUE']\n",
    "    for col in columns_to_clean:\n",
    "        data[col] = data[col].astype(str).str.replace(',', '', regex=False)\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "    # Ensure numeric fields are converted to float where applicable\n",
    "    numeric_columns = ['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'ltp', 'close', 'vwap', '52W L']\n",
    "    for col in numeric_columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "    # Add company name to the data\n",
    "    data['Company'] = company_name\n",
    "\n",
    "    # Handle NaN values\n",
    "    data.fillna(0, inplace=True)\n",
    "\n",
    "    # Connect to the MySQL database and insert data\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = pymysql.connect(**db_config)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Create a table (if it doesn't exist)\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            Date DATE NOT NULL,\n",
    "            series TEXT NOT NULL,\n",
    "            OPEN DOUBLE, HIGH DOUBLE, LOW DOUBLE,\n",
    "            `PREV. CLOSE` DOUBLE, ltp DOUBLE, close DOUBLE, vwap DOUBLE,\n",
    "            `52W H` TEXT, `52W L` DOUBLE, VOLUME TEXT, VALUE TEXT,\n",
    "            `No of trades` TEXT, Company TEXT\n",
    "        );\"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        print(f\"Table '{table_name}' is ready.\")\n",
    "\n",
    "        # Insert data into the MySQL table\n",
    "        insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name} (Date, series, OPEN, HIGH, LOW, `PREV. CLOSE`, ltp, close, vwap,\n",
    "                                  `52W H`, `52W L`, VOLUME, VALUE, `No of trades`, Company)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        for _, row in data.iterrows():\n",
    "            cursor.execute(insert_query, (row['Date'], row['series'], row['OPEN'],\n",
    "                row['HIGH'], row['LOW'], row['PREV. CLOSE'],\n",
    "                row['ltp'], row['close'], row['vwap'],\n",
    "                row['52W H'], row['52W L'], row['VOLUME'],\n",
    "                row['VALUE'], row['No of trades'], row['Company']))\n",
    "\n",
    "        # Commit the transaction\n",
    "        connection.commit()\n",
    "        print(f\"Data inserted successfully into the '{table_name}' table for {company_name}.\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error for {company_name}: {err}\")\n",
    "    finally:\n",
    "        if connection:\n",
    "            connection.close()\n",
    "\n",
    "# Iterate over all companies and process their data\n",
    "for company in companies:\n",
    "    process_company_data(company)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
